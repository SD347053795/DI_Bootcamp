{
  "metadata": {
    "kernelspec": {
      "language": "python",
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "version": "3.6.4",
      "file_extension": ".py",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "name": "python",
      "mimetype": "text/x-python"
    },
    "kaggle": {
      "accelerator": "none",
      "dataSources": [
        {
          "sourceId": 4213024,
          "sourceType": "datasetVersion",
          "datasetId": 2479030
        }
      ],
      "dockerImageVersionId": 30235,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook",
      "isGpuEnabled": false
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat_minor": 0,
  "nbformat": 4,
  "cells": [
    {
      "source": [
        "\n",
        "# IMPORTANT: RUN THIS CELL IN ORDER TO IMPORT YOUR KAGGLE DATA SOURCES\n",
        "# TO THE CORRECT LOCATION (/kaggle/input) IN YOUR NOTEBOOK,\n",
        "# THEN FEEL FREE TO DELETE THIS CELL.\n",
        "# NOTE: THIS NOTEBOOK ENVIRONMENT DIFFERS FROM KAGGLE'S PYTHON\n",
        "# ENVIRONMENT SO THERE MAY BE MISSING LIBRARIES USED BY YOUR\n",
        "# NOTEBOOK.\n",
        "\n",
        "import os\n",
        "import sys\n",
        "from tempfile import NamedTemporaryFile\n",
        "from urllib.request import urlopen\n",
        "from urllib.parse import unquote, urlparse\n",
        "from urllib.error import HTTPError\n",
        "from zipfile import ZipFile\n",
        "import tarfile\n",
        "import shutil\n",
        "\n",
        "CHUNK_SIZE = 40960\n",
        "DATA_SOURCE_MAPPING = 'ab-test-data:https%3A%2F%2Fstorage.googleapis.com%2Fkaggle-data-sets%2F2479030%2F4213024%2Fbundle%2Farchive.zip%3FX-Goog-Algorithm%3DGOOG4-RSA-SHA256%26X-Goog-Credential%3Dgcp-kaggle-com%2540kaggle-161607.iam.gserviceaccount.com%252F20240330%252Fauto%252Fstorage%252Fgoog4_request%26X-Goog-Date%3D20240330T225425Z%26X-Goog-Expires%3D259200%26X-Goog-SignedHeaders%3Dhost%26X-Goog-Signature%3D5f0b86438c0438cdc8ee57c072f48e97fdd4d00520b3ba0f962fb3a7a3578c8f1e855972d2ca87b7dd961d5a62208d7b1407eeb74c7d2a2ed84bcaf1e412e953dc50c86a235fb926ad19af56a7c16ee4a06171c7c33d131b9a2ad6235532a9b454c3f278b72fbd7178fdddaf2e591292c477c9e2bd0a8483b31158c306207a768d97e67bb867139040d8978221a23dd793dd104cc3d85f2e09a7742959d6985e9a7df62e3cc561e1752eac2ec707517e5ec8ad98baaee327e8c3eec01b414d8202bf6ea940cbab62cce4dfef5bf0bc262976b2d3f150eee8835f58f7306037ccc81c48189acb74cae0f45ecab679039f649b7819e1e1820d1f67937886264707'\n",
        "\n",
        "KAGGLE_INPUT_PATH='/kaggle/input'\n",
        "KAGGLE_WORKING_PATH='/kaggle/working'\n",
        "KAGGLE_SYMLINK='kaggle'\n",
        "\n",
        "!umount /kaggle/input/ 2> /dev/null\n",
        "shutil.rmtree('/kaggle/input', ignore_errors=True)\n",
        "os.makedirs(KAGGLE_INPUT_PATH, 0o777, exist_ok=True)\n",
        "os.makedirs(KAGGLE_WORKING_PATH, 0o777, exist_ok=True)\n",
        "\n",
        "try:\n",
        "  os.symlink(KAGGLE_INPUT_PATH, os.path.join(\"..\", 'input'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "try:\n",
        "  os.symlink(KAGGLE_WORKING_PATH, os.path.join(\"..\", 'working'), target_is_directory=True)\n",
        "except FileExistsError:\n",
        "  pass\n",
        "\n",
        "for data_source_mapping in DATA_SOURCE_MAPPING.split(','):\n",
        "    directory, download_url_encoded = data_source_mapping.split(':')\n",
        "    download_url = unquote(download_url_encoded)\n",
        "    filename = urlparse(download_url).path\n",
        "    destination_path = os.path.join(KAGGLE_INPUT_PATH, directory)\n",
        "    try:\n",
        "        with urlopen(download_url) as fileres, NamedTemporaryFile() as tfile:\n",
        "            total_length = fileres.headers['content-length']\n",
        "            print(f'Downloading {directory}, {total_length} bytes compressed')\n",
        "            dl = 0\n",
        "            data = fileres.read(CHUNK_SIZE)\n",
        "            while len(data) > 0:\n",
        "                dl += len(data)\n",
        "                tfile.write(data)\n",
        "                done = int(50 * dl / int(total_length))\n",
        "                sys.stdout.write(f\"\\r[{'=' * done}{' ' * (50-done)}] {dl} bytes downloaded\")\n",
        "                sys.stdout.flush()\n",
        "                data = fileres.read(CHUNK_SIZE)\n",
        "            if filename.endswith('.zip'):\n",
        "              with ZipFile(tfile) as zfile:\n",
        "                zfile.extractall(destination_path)\n",
        "            else:\n",
        "              with tarfile.open(tfile.name) as tarfile:\n",
        "                tarfile.extractall(destination_path)\n",
        "            print(f'\\nDownloaded and uncompressed: {directory}')\n",
        "    except HTTPError as e:\n",
        "        print(f'Failed to load (likely expired) {download_url} to path {destination_path}')\n",
        "        continue\n",
        "    except OSError as e:\n",
        "        print(f'Failed to load {download_url} to path {destination_path}')\n",
        "        continue\n",
        "\n",
        "print('Data source import complete.')\n"
      ],
      "metadata": {
        "id": "s7p0fizhkkpF",
        "outputId": "7ff55f7b-a7c9-43f7-ae98-f9b34f56b166",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "cell_type": "code",
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Failed to load (likely expired) https://storage.googleapis.com/kaggle-data-sets/2479030/4213024/bundle/archive.zip?X-Goog-Algorithm=GOOG4-RSA-SHA256&X-Goog-Credential=gcp-kaggle-com%40kaggle-161607.iam.gserviceaccount.com%2F20240330%2Fauto%2Fstorage%2Fgoog4_request&X-Goog-Date=20240330T225425Z&X-Goog-Expires=259200&X-Goog-SignedHeaders=host&X-Goog-Signature=5f0b86438c0438cdc8ee57c072f48e97fdd4d00520b3ba0f962fb3a7a3578c8f1e855972d2ca87b7dd961d5a62208d7b1407eeb74c7d2a2ed84bcaf1e412e953dc50c86a235fb926ad19af56a7c16ee4a06171c7c33d131b9a2ad6235532a9b454c3f278b72fbd7178fdddaf2e591292c477c9e2bd0a8483b31158c306207a768d97e67bb867139040d8978221a23dd793dd104cc3d85f2e09a7742959d6985e9a7df62e3cc561e1752eac2ec707517e5ec8ad98baaee327e8c3eec01b414d8202bf6ea940cbab62cce4dfef5bf0bc262976b2d3f150eee8835f58f7306037ccc81c48189acb74cae0f45ecab679039f649b7819e1e1820d1f67937886264707 to path /kaggle/input/ab-test-data\n",
            "Data source import complete.\n"
          ]
        }
      ],
      "execution_count": null
    },
    {
      "cell_type": "markdown",
      "source": [
        "The AB test is a randomized experiment that is used by most large companies to evaluate the launch of new functionality. Various difficulties may arise in the analysis and conduct of the experiment. Several typical problematic cases from real life are given in this dataset and analysis."
      ],
      "metadata": {
        "id": "DeHt0ZK0kkpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Content\n",
        "1. [Loading and processing data](#Loading)\n",
        "2. [Statistical Analysis](#Statistical)\n",
        "3. [Conclusions](#Conclusions)"
      ],
      "metadata": {
        "id": "Zm0ogtm1kkpI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading and processing data <a name=\"Loading\"/>"
      ],
      "metadata": {
        "id": "bn40N7ilkkpJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import the necessary libraries and load the data"
      ],
      "metadata": {
        "id": "fh03NWZxkkpJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from scipy.stats import mannwhitneyu\n",
        "from scipy.stats import ttest_ind\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm.auto import tqdm\n",
        "import seaborn as sns\n",
        "from scipy.stats import pearsonr\n",
        "from scipy.stats import shapiro"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:22.571234Z",
          "iopub.execute_input": "2022-09-16T18:23:22.571662Z",
          "iopub.status.idle": "2022-09-16T18:23:22.579386Z",
          "shell.execute_reply.started": "2022-09-16T18:23:22.571624Z",
          "shell.execute_reply": "2022-09-16T18:23:22.577863Z"
        },
        "trusted": true,
        "id": "jKi9SDP2kkpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "path = '/kaggle/input/ab-test-data/AB_Test_Results.csv'\n",
        "df = pd.read_csv(path)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:22.582829Z",
          "iopub.execute_input": "2022-09-16T18:23:22.584216Z",
          "iopub.status.idle": "2022-09-16T18:23:22.604701Z",
          "shell.execute_reply.started": "2022-09-16T18:23:22.584166Z",
          "shell.execute_reply": "2022-09-16T18:23:22.603788Z"
        },
        "trusted": true,
        "id": "5CAgSuFlkkpJ",
        "outputId": "8bc4630a-635d-485d-81ae-b285a55062f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/kaggle/input/ab-test-data/AB_Test_Results.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-8293fc56239e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpath\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/kaggle/input/ab-test-data/AB_Test_Results.csv'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m    910\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    911\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 912\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    575\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    576\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 577\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    578\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1659\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1660\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1661\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1662\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1663\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    857\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    858\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 859\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    860\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    861\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/kaggle/input/ab-test-data/AB_Test_Results.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : take a quick look at the data\n",
        "\n",
        "df.info()\n",
        "df.describe()\n",
        "df.head()\n",
        "df.columns()\n",
        "df.shape()\n",
        "df.isnull().sum() #or df.dropna() depending on the dataset\n",
        "df.drop_duplicates()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:22.606556Z",
          "iopub.execute_input": "2022-09-16T18:23:22.607393Z",
          "iopub.status.idle": "2022-09-16T18:23:22.621022Z",
          "shell.execute_reply.started": "2022-09-16T18:23:22.607349Z",
          "shell.execute_reply": "2022-09-16T18:23:22.619749Z"
        },
        "trusted": true,
        "id": "1nvLy1dIkkpK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see if there are users who have two A/B test groups"
      ],
      "metadata": {
        "id": "gvcmP9L5kkpL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Look at the distribution of the number of unique groups for each user\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "\n",
        "print(\"Distribution of Unique Groups per User:\")\n",
        "print(unique_groups_per_user.describe())\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.hist(unique_groups_per_user, bins=range(1, unique_groups_per_user.max() + 2), edgecolor='black')\n",
        "plt.title('Distribution of Number of Unique Groups per User')\n",
        "plt.xlabel('Number of Unique Groups')\n",
        "plt.ylabel('Frequency')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:22.659897Z",
          "iopub.execute_input": "2022-09-16T18:23:22.660468Z",
          "iopub.status.idle": "2022-09-16T18:23:22.673751Z",
          "shell.execute_reply.started": "2022-09-16T18:23:22.660438Z",
          "shell.execute_reply": "2022-09-16T18:23:22.672845Z"
        },
        "trusted": true,
        "id": "sQfYwAcWkkpL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Look at the distribution of the number of unique groups for each user in relative terms\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "frequency = unique_groups_per_user.value_counts()\n",
        "relative_frequency = frequency / frequency.sum()\n",
        "\n",
        "print(\"Relative Distribution of Unique Groups per User:\")\n",
        "print(relative_frequency)\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.bar(relative_frequency.index, relative_frequency.values, edgecolor='black')\n",
        "plt.title('Relative Distribution of Number of Unique Groups per User')\n",
        "plt.xlabel('Number of Unique Groups')\n",
        "plt.ylabel('Proportion')\n",
        "plt.xticks(relative_frequency.index)\n",
        "plt.grid(True, axis='y')\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:22.675099Z",
          "iopub.execute_input": "2022-09-16T18:23:22.675698Z",
          "iopub.status.idle": "2022-09-16T18:23:22.683077Z",
          "shell.execute_reply.started": "2022-09-16T18:23:22.675666Z",
          "shell.execute_reply": "2022-09-16T18:23:22.682019Z"
        },
        "trusted": true,
        "id": "X7D5HpjdkkpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What can you observe ? Should we exclude these users ? Why ?"
      ],
      "metadata": {
        "id": "gyhapbJkkkpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : users have 1 A/B test group ?\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1]\n",
        "print(f\"Number of users with exactly one A/B test group: {len(users_with_one_group)}\")\n",
        "print(\"\\nSample of users with exactly one A/B test group:\")\n",
        "print(users_with_one_group.head())\n",
        "\n",
        "# TODO : Take only these users\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "print(\"Filtered DataFrame Info:\")\n",
        "print(filtered_df.info())\n",
        "print(\"\\nSample of Filtered DataFrame:\")\n",
        "print(filtered_df.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:22.684621Z",
          "iopub.execute_input": "2022-09-16T18:23:22.68523Z",
          "iopub.status.idle": "2022-09-16T18:23:22.704635Z",
          "shell.execute_reply.started": "2022-09-16T18:23:22.685198Z",
          "shell.execute_reply": "2022-09-16T18:23:22.70344Z"
        },
        "trusted": true,
        "id": "MNRylCuikkpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Leave only records with users with the 1st ab test group\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "print(\"Final Filtered DataFrame Info:\")\n",
        "print(final_filtered_df.info())\n",
        "print(\"\\nSample of Final Filtered DataFrame:\")\n",
        "print(final_filtered_df.head())\n",
        "\n",
        "\n",
        "# TODO : Check that the number of users matches what it was before the exception\n",
        "\n",
        "unique_groups_per_user = final_filtered_df.groupby('user')['group'].nunique()\n",
        "print(f\"Number of users with exactly one A/B test group: {len(unique_groups_per_user)}\")\n",
        "\n",
        "initial_user_count = df['user'].nunique()\n",
        "final_user_count = final_filtered_df['user'].nunique()\n",
        "print(f\"Initial number of unique users: {initial_user_count}\")\n",
        "print(f\"Final number of unique users: {final_user_count}\")\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "final_user_count = final_filtered_df['user'].nunique()\n",
        "print(f\"Initial number of unique users: {initial_user_count}\")\n",
        "print(f\"Number of unique users after final filtering: {final_user_count}\")\n",
        "\n",
        "if initial_user_count == final_user_count:\n",
        "    print(\"The number of unique users matches before and after filtering.\")\n",
        "else:\n",
        "    print(\"The number of unique users does not match before and after filtering.\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:22.706067Z",
          "iopub.execute_input": "2022-09-16T18:23:22.707214Z",
          "iopub.status.idle": "2022-09-16T18:23:22.721546Z",
          "shell.execute_reply.started": "2022-09-16T18:23:22.70718Z",
          "shell.execute_reply": "2022-09-16T18:23:22.720237Z"
        },
        "trusted": true,
        "id": "4XvAx6ZtkkpM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's see how the data is distributed"
      ],
      "metadata": {
        "id": "Vpvcse3pkkpM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Check how the data is distributed using a box plot\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "numerical_column = 'some_numeric_column'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=final_filtered_df, x='group', y=numerical_column)\n",
        "plt.title('Box Plot of Numerical Column Distribution')\n",
        "plt.xlabel('A/B Test Group')\n",
        "plt.ylabel('Values of Numerical Column')\n",
        "plt.grid(True)\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:22.722862Z",
          "iopub.execute_input": "2022-09-16T18:23:22.723766Z",
          "iopub.status.idle": "2022-09-16T18:23:22.98119Z",
          "shell.execute_reply.started": "2022-09-16T18:23:22.723732Z",
          "shell.execute_reply": "2022-09-16T18:23:22.980008Z"
        },
        "trusted": true,
        "id": "EW1ZGmsukkpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It can be seen that there is a strong outlier in the data - we will find it by sorting these revenue values in descending order"
      ],
      "metadata": {
        "id": "Hlp3psWykkpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Sort these revenue values in descending order\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "revenue_column = 'revenue'\n",
        "sorted_revenue_df = final_filtered_df.sort_values(by=revenue_column, ascending=False)\n",
        "print(\"Sorted Revenue Values:\")\n",
        "print(sorted_revenue_df[[revenue_column]].head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:22.986753Z",
          "iopub.execute_input": "2022-09-16T18:23:22.987116Z",
          "iopub.status.idle": "2022-09-16T18:23:23.005356Z",
          "shell.execute_reply.started": "2022-09-16T18:23:22.987087Z",
          "shell.execute_reply": "2022-09-16T18:23:23.004381Z"
        },
        "trusted": true,
        "id": "9O6xaJmOkkpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : See if user 3342 had other events with a strong outlier\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "\n",
        "user_df = final_filtered_df[final_filtered_df['user'] == 3342]\n",
        "numerical_column = 'some_numeric_column'\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=user_df[numerical_column])\n",
        "plt.title(f'Box Plot of {numerical_column} for User 3342')\n",
        "plt.xlabel(numerical_column)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "Q1 = user_df[numerical_column].quantile(0.25)\n",
        "Q3 = user_df[numerical_column].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "outliers = user_df[(user_df[numerical_column] < (Q1 - 1.5 * IQR)) | (user_df[numerical_column] > (Q3 + 1.5 * IQR))]\n",
        "print(f\"Number of strong outliers for user 3342: {outliers.shape[0]}\")\n",
        "print(\"Strong outliers:\")\n",
        "print(outliers[[numerical_column]])"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:23.009204Z",
          "iopub.execute_input": "2022-09-16T18:23:23.009563Z",
          "iopub.status.idle": "2022-09-16T18:23:23.022364Z",
          "shell.execute_reply.started": "2022-09-16T18:23:23.009514Z",
          "shell.execute_reply": "2022-09-16T18:23:23.020814Z"
        },
        "trusted": true,
        "id": "zzX8JJiIkkpN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that there is only one outlier - in conditions of limited information, we will remove this entry and look at the distribution of data again"
      ],
      "metadata": {
        "id": "rvfqeZW6kkpN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : We see that there is only one outlier - in conditions of limited information, remove this entry and visualize the distribution of data again.\n",
        "\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "user_df = final_filtered_df[final_filtered_df['user'] == 3342]\n",
        "numerical_column = 'some_numeric_column'\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=user_df[numerical_column])\n",
        "plt.title(f'Box Plot of {numerical_column} for User 3342')\n",
        "plt.xlabel(numerical_column)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "Q1 = user_df[numerical_column].quantile(0.25)\n",
        "Q3 = user_df[numerical_column].quantile(0.75)\n",
        "IQR = Q3 - Q1\n",
        "\n",
        "outliers = user_df[(user_df[numerical_column] < (Q1 - 1.5 * IQR)) | (user_df[numerical_column] > (Q3 + 1.5 * IQR))]\n",
        "cleaned_user_df = user_df[~user_df.index.isin(outliers.index)]\n",
        "updated_final_filtered_df = final_filtered_df[~final_filtered_df.index.isin(outliers.index)]\n",
        "\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(x=updated_final_filtered_df[numerical_column])\n",
        "plt.title(f'Box Plot of {numerical_column} After Removing Outlier')\n",
        "plt.xlabel(numerical_column)\n",
        "plt.grid(True)\n",
        "plt.show()\n",
        "\n",
        "print(f\"Number of strong outliers for user 3342 removed: {outliers.shape[0]}\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:23.024282Z",
          "iopub.execute_input": "2022-09-16T18:23:23.024763Z",
          "iopub.status.idle": "2022-09-16T18:23:23.031917Z",
          "shell.execute_reply.started": "2022-09-16T18:23:23.024711Z",
          "shell.execute_reply": "2022-09-16T18:23:23.030566Z"
        },
        "trusted": true,
        "id": "9VHXOhaVkkpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "What can you say about the users and their purchases ?"
      ],
      "metadata": {
        "id": "r8pN_6oekkpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Check if there are users who have records with zero and positive revenue\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "\n",
        "revenue_column = 'revenue'\n",
        "users_with_zero_revenue = final_filtered_df[final_filtered_df[revenue_column] == 0]['user'].unique()\n",
        "users_with_positive_revenue = final_filtered_df[final_filtered_df[revenue_column] > 0]['user'].unique()\n",
        "users_with_both = set(users_with_zero_revenue).intersection(users_with_positive_revenue)\n",
        "\n",
        "print(f\"Number of users with both zero and positive revenue: {len(users_with_both)}\")\n",
        "print(\"List of users with both zero and positive revenue:\")\n",
        "print(users_with_both)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:23.396475Z",
          "iopub.execute_input": "2022-09-16T18:23:23.397266Z",
          "iopub.status.idle": "2022-09-16T18:23:23.4091Z",
          "shell.execute_reply.started": "2022-09-16T18:23:23.397231Z",
          "shell.execute_reply": "2022-09-16T18:23:23.407843Z"
        },
        "trusted": true,
        "id": "VZ3v8TeekkpO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Can a user have records with both zero and positive revenue ?\n",
        "\n",
        "Let's make the assumption that the records are user visits to the service, and the experimental unit is users.\n"
      ],
      "metadata": {
        "id": "u_G7PRphkkpO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Group the data for each user and sum the revenue for each to get one record per user\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "\n",
        "revenue_column = 'revenue'\n",
        "user_revenue_sum = final_filtered_df.groupby('user')[revenue_column].sum().reset_index()\n",
        "user_revenue_sum.columns = ['user', 'total_revenue']\n",
        "print(\"Aggregated Data (Total Revenue per User):\")\n",
        "print(user_revenue_sum.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:23.410519Z",
          "iopub.execute_input": "2022-09-16T18:23:23.411317Z",
          "iopub.status.idle": "2022-09-16T18:23:23.425157Z",
          "shell.execute_reply.started": "2022-09-16T18:23:23.411275Z",
          "shell.execute_reply": "2022-09-16T18:23:23.423982Z"
        },
        "trusted": true,
        "id": "R5GdAtTXkkpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Visualize the resulting distribution of the data again.\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "\n",
        "revenue_column = 'revenue'\n",
        "user_revenue_sum = final_filtered_df.groupby('user')[revenue_column].sum().reset_index()\n",
        "user_revenue_sum.columns = ['user', 'total_revenue']\n",
        "\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.histplot(user_revenue_sum['total_revenue'], bins=30, kde=True)\n",
        "plt.title('Histogram of Total Revenue per User')\n",
        "plt.xlabel('Total Revenue')\n",
        "plt.ylabel('Frequency')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.boxplot(x=user_revenue_sum['total_revenue'])\n",
        "plt.title('Box Plot of Total Revenue per User')\n",
        "plt.xlabel('Total Revenue')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:23.428689Z",
          "iopub.execute_input": "2022-09-16T18:23:23.428999Z",
          "iopub.status.idle": "2022-09-16T18:23:23.783807Z",
          "shell.execute_reply.started": "2022-09-16T18:23:23.428972Z",
          "shell.execute_reply": "2022-09-16T18:23:23.782679Z"
        },
        "trusted": true,
        "id": "Q7H93ZwNkkpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "It should be noted that during the transformation, the quantiles in the test group increased\n",
        "\n",
        "It can be seen that in the test group, almost all quantile statistics, except for the minimum, are at a slightly lower level.\n",
        "\n",
        "Let's look at various statistics in the context of AB test groups for all users"
      ],
      "metadata": {
        "id": "_NTyRweHkkpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : get metrics by groups\n",
        "# TODO : create two additional metrics to see relative changes\n",
        "# TODO : add them to the rest of the metrics in a separate group\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "\n",
        "revenue_column = 'revenue'\n",
        "metrics_by_group = final_filtered_df.groupby('group')[revenue_column].agg(['mean', 'median', 'std', 'count']).reset_index()\n",
        "metrics_by_group.columns = ['group', 'mean_revenue', 'median_revenue', 'std_revenue', 'count_records']\n",
        "overall_mean_revenue = metrics_by_group['mean_revenue'].mean()\n",
        "metrics_by_group['relative_change_from_mean'] = (metrics_by_group['mean_revenue'] - overall_mean_revenue) / overall_mean_revenue\n",
        "baseline_group = metrics_by_group['group'].iloc[0]\n",
        "baseline_mean_revenue = metrics_by_group[metrics_by_group['group'] == baseline_group]['mean_revenue'].values[0]\n",
        "\n",
        "metrics_by_group['percentage_change_from_baseline'] = ((metrics_by_group['mean_revenue'] - baseline_mean_revenue) / baseline_mean_revenue) * 100\n",
        "\n",
        "print(\"Combined Metrics by A/B Test Group:\")\n",
        "print(metrics_by_group)\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(16, 10))\n",
        "\n",
        "# Plot Mean Revenue by Group\n",
        "plt.subplot(3, 2, 1)\n",
        "sns.barplot(x='group', y='mean_revenue', data=metrics_by_group, palette='viridis')\n",
        "plt.title('Mean Revenue by Group')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Mean Revenue')\n",
        "\n",
        "# Plot Median Revenue by Group\n",
        "plt.subplot(3, 2, 2)\n",
        "sns.barplot(x='group', y='median_revenue', data=metrics_by_group, palette='viridis')\n",
        "plt.title('Median Revenue by Group')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Median Revenue')\n",
        "\n",
        "# Plot Standard Deviation of Revenue by Group\n",
        "plt.subplot(3, 2, 3)\n",
        "sns.barplot(x='group', y='std_revenue', data=metrics_by_group, palette='viridis')\n",
        "plt.title('Standard Deviation of Revenue by Group')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Standard Deviation')\n",
        "\n",
        "# Plot Count of Records by Group\n",
        "plt.subplot(3, 2, 4)\n",
        "sns.barplot(x='group', y='count_records', data=metrics_by_group, palette='viridis')\n",
        "plt.title('Count of Records by Group')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Count of Records')\n",
        "\n",
        "# Plot Relative Change from Mean\n",
        "plt.subplot(3, 2, 5)\n",
        "sns.barplot(x='group', y='relative_change_from_mean', data=metrics_by_group, palette='viridis')\n",
        "plt.title('Relative Change from Mean Revenue')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Relative Change')\n",
        "\n",
        "# Plot Percentage Change from Baseline\n",
        "plt.subplot(3, 2, 6)\n",
        "sns.barplot(x='group', y='percentage_change_from_baseline', data=metrics_by_group, palette='viridis')\n",
        "plt.title('Percentage Change from Baseline Revenue')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Percentage Change')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:23.785212Z",
          "iopub.execute_input": "2022-09-16T18:23:23.78594Z",
          "iopub.status.idle": "2022-09-16T18:23:23.813162Z",
          "shell.execute_reply.started": "2022-09-16T18:23:23.785905Z",
          "shell.execute_reply": "2022-09-16T18:23:23.812388Z"
        },
        "trusted": true,
        "id": "9QF5FZTAkkpP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What can you see in the test group about the total amount of revenue, the average check per user, and the number of orders per user slightly increased ?\n",
        "\n",
        "Let's also see how paying users behave :"
      ],
      "metadata": {
        "id": "-FEgWEXckkpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : get metrics by groups\n",
        "# TODO : create two additional metrics to see relative changes\n",
        "# TODO : add them to the rest of the metrics in a separate group\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "\n",
        "revenue_column = 'revenue'\n",
        "basic_metrics_by_group = final_filtered_df.groupby('group')[revenue_column].agg(['mean', 'median', 'std', 'count']).reset_index()\n",
        "basic_metrics_by_group.columns = ['group', 'mean_revenue', 'median_revenue', 'std_revenue', 'count_records']\n",
        "overall_mean_revenue = basic_metrics_by_group['mean_revenue'].mean()\n",
        "basic_metrics_by_group['relative_change_from_mean'] = (basic_metrics_by_group['mean_revenue'] - overall_mean_revenue) / overall_mean_revenue\n",
        "baseline_group = basic_metrics_by_group['group'].iloc[0]\n",
        "baseline_mean_revenue = basic_metrics_by_group[basic_metrics_by_group['group'] == baseline_group]['mean_revenue'].values[0]\n",
        "basic_metrics_by_group['percentage_change_from_baseline'] = ((basic_metrics_by_group['mean_revenue'] - baseline_mean_revenue) / baseline_mean_revenue) * 100\n",
        "print(\"Combined Metrics by A/B Test Group:\")\n",
        "print(basic_metrics_by_group)\n",
        "\n",
        "sns.set(style=\"whitegrid\")\n",
        "plt.figure(figsize=(16, 12))\n",
        "\n",
        "# Plot Mean Revenue by Group\n",
        "plt.subplot(3, 2, 1)\n",
        "sns.barplot(x='group', y='mean_revenue', data=basic_metrics_by_group, palette='viridis')\n",
        "plt.title('Mean Revenue by Group')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Mean Revenue')\n",
        "\n",
        "# Plot Median Revenue by Group\n",
        "plt.subplot(3, 2, 2)\n",
        "sns.barplot(x='group', y='median_revenue', data=basic_metrics_by_group, palette='viridis')\n",
        "plt.title('Median Revenue by Group')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Median Revenue')\n",
        "\n",
        "# Plot Standard Deviation of Revenue by Group\n",
        "plt.subplot(3, 2, 3)\n",
        "sns.barplot(x='group', y='std_revenue', data=basic_metrics_by_group, palette='viridis')\n",
        "plt.title('Standard Deviation of Revenue by Group')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Standard Deviation')\n",
        "\n",
        "# Plot Count of Records by Group\n",
        "plt.subplot(3, 2, 4)\n",
        "sns.barplot(x='group', y='count_records', data=basic_metrics_by_group, palette='viridis')\n",
        "plt.title('Count of Records by Group')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Count of Records')\n",
        "\n",
        "# Plot Relative Change from Mean\n",
        "plt.subplot(3, 2, 5)\n",
        "sns.barplot(x='group', y='relative_change_from_mean', data=basic_metrics_by_group, palette='viridis')\n",
        "plt.title('Relative Change from Mean Revenue')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Relative Change')\n",
        "\n",
        "# Plot Percentage Change from Baseline\n",
        "plt.subplot(3, 2, 6)\n",
        "sns.barplot(x='group', y='percentage_change_from_baseline', data=basic_metrics_by_group, palette='viridis')\n",
        "plt.title('Percentage Change from Baseline Revenue')\n",
        "plt.xlabel('Group')\n",
        "plt.ylabel('Percentage Change')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:23.814201Z",
          "iopub.execute_input": "2022-09-16T18:23:23.814781Z",
          "iopub.status.idle": "2022-09-16T18:23:23.842362Z",
          "shell.execute_reply.started": "2022-09-16T18:23:23.814749Z",
          "shell.execute_reply": "2022-09-16T18:23:23.841593Z"
        },
        "trusted": true,
        "id": "ZM1LQ1VrkkpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the distributions of all and only paying users"
      ],
      "metadata": {
        "id": "RozYt1eZkkpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, axes = plt.subplots(2, figsize=(10,8))\n",
        "# build graphs of distributions of all users\n",
        "sns.distplot(df.loc[df['VARIANT_NAME'] == 'control', 'REVENUE'], ax = axes[0], label='control')\n",
        "sns.distplot(df.loc[df['VARIANT_NAME'] == 'variant', 'REVENUE'], ax = axes[0], label='variant')\n",
        "axes[0].set_title('Distribution of revenue of all users')\n",
        "\n",
        "# build graphs of distributions of paying users\n",
        "sns.distplot(df.loc[(df['VARIANT_NAME'] == 'control') & (df['REVENUE'] > 0), 'REVENUE'], ax = axes[1], label='control' )\n",
        "sns.distplot(df.loc[(df['VARIANT_NAME'] == 'variant') & (df['REVENUE'] > 0), 'REVENUE'], ax = axes[1], label='variant' )\n",
        "axes[1].set_title('Paying user revenue distribution')\n",
        "plt.legend()\n",
        "plt.subplots_adjust(hspace = 0.3)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:23.843826Z",
          "iopub.execute_input": "2022-09-16T18:23:23.844477Z",
          "iopub.status.idle": "2022-09-16T18:23:24.587221Z",
          "shell.execute_reply.started": "2022-09-16T18:23:23.844435Z",
          "shell.execute_reply": "2022-09-16T18:23:24.585887Z"
        },
        "trusted": true,
        "id": "Xmm-HM-ZkkpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Statistical Analysis <a name=\"Statistical\"/>"
      ],
      "metadata": {
        "id": "5vwsQSeVkkpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Checking if the distribution is normal"
      ],
      "metadata": {
        "id": "lJP78Hc_kkpQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Based on their previous graph, we see that the data is not normally distributed."
      ],
      "metadata": {
        "id": "BVRKdz3WkkpQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Use the Shapiro-Wilk criterion to confirm it\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_df['group'].unique()[0]\n",
        "final_filtered_df = filtered_df[filtered_df['group'] == first_ab_test_group]\n",
        "revenue_column = 'revenue'\n",
        "revenue_data = final_filtered_df[revenue_column]\n",
        "stat, p_value = stats.shapiro(revenue_data)\n",
        "\n",
        "print(f\"Shapiro-Wilk Test Statistic: {stat}\")\n",
        "print(f\"Shapiro-Wilk p-value: {p_value}\")\n",
        "\n",
        "alpha = 0.05\n",
        "if p_value > alpha:\n",
        "    print(\"The data appears to be normally distributed (fail to reject H0).\")\n",
        "else:\n",
        "    print(\"The data does not appear to be normally distributed (reject H0).\")"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:24.588685Z",
          "iopub.execute_input": "2022-09-16T18:23:24.589024Z",
          "iopub.status.idle": "2022-09-16T18:23:24.597871Z",
          "shell.execute_reply.started": "2022-09-16T18:23:24.588995Z",
          "shell.execute_reply": "2022-09-16T18:23:24.596794Z"
        },
        "trusted": true,
        "id": "je2NXscMkkpQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Is the null hypothesis about the normal distribution of the data rejected ?"
      ],
      "metadata": {
        "id": "Pq-RbAERkkpR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Mann-Whitney test"
      ],
      "metadata": {
        "id": "nYxHXTxpkkpR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check the value of the statistics of the Mann-Whitney test. Some sources have a limitation of applicability in case of duplicate data. There are a lot of repetitions in our sample, and especially a lot of zero values, so in this case we need to be careful about this criterion."
      ],
      "metadata": {
        "id": "eGKBrlFnkkpR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "(df['REVENUE'] == 0).value_counts()"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:24.599408Z",
          "iopub.execute_input": "2022-09-16T18:23:24.600052Z",
          "iopub.status.idle": "2022-09-16T18:23:24.609697Z",
          "shell.execute_reply.started": "2022-09-16T18:23:24.600019Z",
          "shell.execute_reply": "2022-09-16T18:23:24.608442Z"
        },
        "trusted": true,
        "id": "ftj_LlaZkkpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Check on the data of all users the value of the statistics of the Mann-Whitney test\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "unique_groups_per_user = df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_df = df[df['user'].isin(users_with_one_group)]\n",
        "\n",
        "revenue_column = 'revenue'\n",
        "groups = filtered_df['group'].unique()\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in range(len(groups)):\n",
        "    for j in range(i + 1, len(groups)):\n",
        "        group1 = groups[i]\n",
        "        group2 = groups[j]\n",
        "\n",
        "\n",
        "        data_group1 = filtered_df[filtered_df['group'] == group1][revenue_column]\n",
        "        data_group2 = filtered_df[filtered_df['group'] == group2][revenue_column]\n",
        "\n",
        "\n",
        "        stat, p_value = stats.mannwhitneyu(data_group1, data_group2, alternative='two-sided')\n",
        "\n",
        "        results.append({\n",
        "            'Group1': group1,\n",
        "            'Group2': group2,\n",
        "            'Mann-Whitney U Statistic': stat,\n",
        "            'p-value': p_value\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "print(\"Mann-Whitney U Test Results:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:24.611079Z",
          "iopub.execute_input": "2022-09-16T18:23:24.611478Z",
          "iopub.status.idle": "2022-09-16T18:23:24.627499Z",
          "shell.execute_reply.started": "2022-09-16T18:23:24.611448Z",
          "shell.execute_reply": "2022-09-16T18:23:24.626266Z"
        },
        "trusted": true,
        "id": "liLsCl00kkpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Check on the data of only the users that pay, the value of the statistics of the Mann-Whitney test\n",
        "\n",
        "import scipy.stats as stats\n",
        "\n",
        "paying_users_df = df[df['revenue'] > 0]\n",
        "unique_groups_per_user = paying_users_df.groupby('user')['group'].nunique()\n",
        "users_with_one_group = unique_groups_per_user[unique_groups_per_user == 1].index\n",
        "filtered_paying_df = paying_users_df[paying_users_df['user'].isin(users_with_one_group)]\n",
        "first_ab_test_group = filtered_paying_df['group'].unique()[0]\n",
        "filtered_paying_df = filtered_paying_df[filtered_paying_df['group'] == first_ab_test_group]\n",
        "revenue_column = 'revenue'\n",
        "groups = filtered_paying_df['group'].unique()\n",
        "\n",
        "results = []\n",
        "\n",
        "for i in range(len(groups)):\n",
        "    for j in range(i + 1, len(groups)):\n",
        "        group1 = groups[i]\n",
        "        group2 = groups[j]\n",
        "\n",
        "        data_group1 = filtered_paying_df[filtered_paying_df['group'] == group1][revenue_column]\n",
        "        data_group2 = filtered_paying_df[filtered_paying_df['group'] == group2][revenue_column]\n",
        "\n",
        "        stat, p_value = stats.mannwhitneyu(data_group1, data_group2, alternative='two-sided')\n",
        "\n",
        "        results.append({\n",
        "            'Group1': group1,\n",
        "            'Group2': group2,\n",
        "            'Mann-Whitney U Statistic': stat,\n",
        "            'p-value': p_value\n",
        "        })\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "\n",
        "print(\"Mann-Whitney U Test Results for Paying Users:\")\n",
        "print(results_df)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:24.632144Z",
          "iopub.execute_input": "2022-09-16T18:23:24.632496Z",
          "iopub.status.idle": "2022-09-16T18:23:24.644752Z",
          "shell.execute_reply.started": "2022-09-16T18:23:24.632466Z",
          "shell.execute_reply": "2022-09-16T18:23:24.643569Z"
        },
        "trusted": true,
        "id": "tCCcVEM4kkpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Bootstrap"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T17:49:10.3638Z",
          "iopub.execute_input": "2022-09-16T17:49:10.365079Z",
          "iopub.status.idle": "2022-09-16T17:49:10.369587Z",
          "shell.execute_reply.started": "2022-09-16T17:49:10.365037Z",
          "shell.execute_reply": "2022-09-16T17:49:10.368719Z"
        },
        "id": "XBp259a8kkpS"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to get more complete information about the differences between the average values of the ab test groups, we will use bootstap.\n",
        "\n",
        "Let's create a function to get back samples and get a confidence interval, and then look at the sample statistics"
      ],
      "metadata": {
        "id": "0xpO-CmekkpS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_bootstrap_samples(data, n_samples=1000):\n",
        "    indices = np.random.randint(0, len(data), (n_samples, len(data)))\n",
        "    samples = data[indices]\n",
        "    return samples\n",
        "\n",
        "def stat_intervals(stat, alpha=0.05):\n",
        "    boundaries = np.percentile(stat, [100 * alpha / 2., 100 * (1 - alpha / 2.)])\n",
        "    return boundaries"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:24.645844Z",
          "iopub.execute_input": "2022-09-16T18:23:24.646134Z",
          "iopub.status.idle": "2022-09-16T18:23:24.653955Z",
          "shell.execute_reply.started": "2022-09-16T18:23:24.646108Z",
          "shell.execute_reply": "2022-09-16T18:23:24.652612Z"
        },
        "trusted": true,
        "id": "3yLh1toVkkpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Generate samples for all users\n",
        "\n",
        "sample_size = 10\n",
        "samples = []\n",
        "\n",
        "grouped = df.groupby('user')\n",
        "\n",
        "for user, group_data in grouped:\n",
        "    if len(group_data) > sample_size:\n",
        "        sampled_data = group_data.sample(n=sample_size, random_state=42)\n",
        "    else:\n",
        "        sampled_data = group_data\n",
        "    samples.append(sampled_data)\n",
        "sampled_df = pd.concat(samples).reset_index(drop=True)\n",
        "\n",
        "print(\"Sampled Data for All Users:\")\n",
        "print(sampled_df.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:24.656318Z",
          "iopub.execute_input": "2022-09-16T18:23:24.656775Z",
          "iopub.status.idle": "2022-09-16T18:23:25.935543Z",
          "shell.execute_reply.started": "2022-09-16T18:23:24.656733Z",
          "shell.execute_reply": "2022-09-16T18:23:25.934505Z"
        },
        "trusted": true,
        "id": "vAgJqb7lkkpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# TODO : Generate samples for only paying users\n",
        "\n",
        "paying_users_df = df[df['revenue'] > 0]\n",
        "sample_size = 10\n",
        "samples = []\n",
        "grouped = paying_users_df.groupby('user')\n",
        "\n",
        "for user, group_data in grouped:\n",
        "    if len(group_data) > sample_size:\n",
        "        sampled_data = group_data.sample(n=sample_size, random_state=42)\n",
        "    else:\n",
        "        sampled_data = group_data\n",
        "    samples.append(sampled_data)\n",
        "\n",
        "sampled_paying_df = pd.concat(samples).reset_index(drop=True)\n",
        "\n",
        "print(\"Sampled Data for Paying Users:\")\n",
        "print(sampled_paying_df.head())"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:25.936759Z",
          "iopub.execute_input": "2022-09-16T18:23:25.937087Z",
          "iopub.status.idle": "2022-09-16T18:23:25.964331Z",
          "shell.execute_reply.started": "2022-09-16T18:23:25.937057Z",
          "shell.execute_reply": "2022-09-16T18:23:25.96321Z"
        },
        "trusted": true,
        "id": "pwXNe9H4kkpS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's look at the distribution of means in the ab test groups"
      ],
      "metadata": {
        "id": "7OsUPGxnkkpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots()\n",
        "# plt.figure(figsize=(20,5))\n",
        "sns.kdeplot(np.mean(control, axis=1), shade=True, label='control')\n",
        "sns.kdeplot(np.mean(variant, axis=1), shade=True, label='variant')\n",
        "plt.title('Sample mean distribution for all users')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:25.965453Z",
          "iopub.execute_input": "2022-09-16T18:23:25.96576Z",
          "iopub.status.idle": "2022-09-16T18:23:26.299852Z",
          "shell.execute_reply.started": "2022-09-16T18:23:25.965732Z",
          "shell.execute_reply": "2022-09-16T18:23:26.298725Z"
        },
        "trusted": true,
        "id": "CvNnX2ALkkpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f, ax = plt.subplots()\n",
        "# plt.figure(figsize=(20,5))\n",
        "sns.kdeplot(np.mean(control_paid, axis=1), shade=True, label='control')\n",
        "sns.kdeplot(np.mean(variant_paid, axis=1), shade=True, label='variant')\n",
        "plt.title('Sample mean distribution for paying users')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:26.301272Z",
          "iopub.execute_input": "2022-09-16T18:23:26.301641Z",
          "iopub.status.idle": "2022-09-16T18:23:26.62483Z",
          "shell.execute_reply.started": "2022-09-16T18:23:26.301609Z",
          "shell.execute_reply": "2022-09-16T18:23:26.623431Z"
        },
        "trusted": true,
        "id": "v4_qUms4kkpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Do you see any difference ? What about the confidence intervals ? Conclude.\n",
        "\n",
        "Let's evaluate the difference between the groups: look at the distribution of the mean difference and build confidence intervals for it. To do this, we will create a function for visualization"
      ],
      "metadata": {
        "id": "8MXUz0CEkkpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_distribution_and_stat_intervals(variant, control, title, alpha=0.05):\n",
        "    \"\"\" Plot the distribution of the mean difference and return the confidence intervals \"\"\"\n",
        "    f, ax = plt.subplots()\n",
        "    # get data for coloring confidence intervals\n",
        "    points = sns.kdeplot(variant - control, shade=True).get_lines()[0].get_data()\n",
        "    x = points[0]\n",
        "    y = points[1]\n",
        "    ymin, ymax = plt.ylim()\n",
        "    # highlight the zero value and the bounds of the confidence interval\n",
        "    plt.vlines(0, 0, ymax, label='0', color='gray')\n",
        "    plt.vlines(stat_intervals(variant - control, alpha)[0], 0, ymax, linestyles=\"dashed\")\n",
        "    plt.vlines(stat_intervals(variant - control, alpha)[1], 0, ymax, linestyles=\"dashed\")\n",
        "    # color the confidence interval and zones outside it\n",
        "    plt.fill_between(x,y,\n",
        "                     where = (x >= stat_intervals(variant - control, alpha)[1]),\n",
        "                     color='gainsboro')\n",
        "    plt.fill_between(x,y,\n",
        "                     where = (x <= stat_intervals(variant - control, alpha)[0]),\n",
        "                     color='gainsboro')\n",
        "    plt.fill_between(x,y,\n",
        "                     where = ((x >= stat_intervals(variant - control, alpha)[0])\n",
        "                              & (x <= stat_intervals(variant - control, alpha)[1])),\n",
        "                     color='red',\n",
        "                     label = '95% confidence interval')\n",
        "    plt.title(f'Distribution of difference between means (variant - control) {title}; {100*(1-alpha)}% Confidence interval for difference of means: {stat_intervals(variant - control, alpha)}')\n",
        "    plt.legend(prop={'size':13})\n",
        "    # return confidence interval data\n",
        "    return stat_intervals(variant - control)"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:26.62643Z",
          "iopub.execute_input": "2022-09-16T18:23:26.628052Z",
          "iopub.status.idle": "2022-09-16T18:23:26.639469Z",
          "shell.execute_reply.started": "2022-09-16T18:23:26.628017Z",
          "shell.execute_reply": "2022-09-16T18:23:26.638694Z"
        },
        "trusted": true,
        "id": "bBIz3jkCkkpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's build a graph of the distribution of the difference in the means and get a confidence interval\n",
        "\n",
        "For all users"
      ],
      "metadata": {
        "id": "ZIUmqXtHkkpT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_distribution_and_stat_intervals(np.mean(variant, axis=1),\n",
        "                                     np.mean(control, axis=1),\n",
        "                                     title='all users')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:26.640692Z",
          "iopub.execute_input": "2022-09-16T18:23:26.641004Z",
          "iopub.status.idle": "2022-09-16T18:23:26.655336Z",
          "shell.execute_reply.started": "2022-09-16T18:23:26.640977Z",
          "shell.execute_reply": "2022-09-16T18:23:26.654163Z"
        },
        "trusted": true,
        "id": "eQq8UewNkkpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_distribution_and_stat_intervals(np.mean(variant_paid, axis=1),\n",
        "                                     np.mean(control_paid, axis=1),\n",
        "                                     title='paying users')"
      ],
      "metadata": {
        "execution": {
          "iopub.status.busy": "2022-09-16T18:23:26.656914Z",
          "iopub.execute_input": "2022-09-16T18:23:26.657231Z",
          "iopub.status.idle": "2022-09-16T18:23:26.666176Z",
          "shell.execute_reply.started": "2022-09-16T18:23:26.65719Z",
          "shell.execute_reply": "2022-09-16T18:23:26.664922Z"
        },
        "trusted": true,
        "id": "mOb8VkPAkkpT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "What can you observe ? Conclude about the statistical change in average revenue between A/B test groups.\n"
      ],
      "metadata": {
        "id": "5KFSGNjOkkpU"
      }
    }
  ]
}