{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ITZzkcYS0iM"
      },
      "outputs": [],
      "source": [
        "#In Google Sheets this can also be completed by clicking on Data then Data Cleanup then Remove Duplicates\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "titanic_df = pd.read_csv(\"C:\\Users\\Shmuel\\Desktop\\DI_Bootcamp\\Week 8\\Day M2\\Exercises\\Titanic_Dataset.csv\");\n",
        "\n",
        "duplicates = titanic_df.duplicated()\n",
        "print(f'Number of duplicate rows: {duplicates.sum()}')\n",
        "\n",
        "titanic_df_cleaned = titanic_df.drop_duplicates()\n",
        "\n",
        "print(f'Number of rows before removing duplicates: {titanic_df.shape[0]}')\n",
        "print(f'Number of rows after removing duplicates: {titanic_df_cleaned.shape[0]}')\n",
        "\n",
        "if titanic_df.shape[0] > titanic_df_cleaned.shape[0]:\n",
        "    print('Duplicates were removed successfully.')\n",
        "else:\n",
        "    print('No duplicates were found or removed.')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "titanic_df = pd.read_csv('C:/Users/Shmuel/Desktop/DI_Bootcamp/Week 8/Day M2/Exercises/Titanic_Dataset.csv')\n",
        "\n",
        "missing_values = titanic_df.isnull().sum()\n",
        "print(\"Columns with missing values:\\n\", missing_values[missing_values > 0])\n",
        "\n",
        "titanic_dropped_rows = titanic_df.dropna()\n",
        "\n",
        "titanic_dropped_columns = titanic_df.dropna(axis=1)\n",
        "\n",
        "print(f'Original number of rows: {titanic_df.shape[0]}')\n",
        "print(f'Number of rows after dropping rows with missing values: {titanic_dropped_rows.shape[0]}')\n",
        "print(f'Number of columns after dropping columns with missing values: {titanic_dropped_columns.shape[1]}')\n",
        "\n",
        "titanic_df['Age'] = titanic_df['Age'].fillna(titanic_df['Age'].median())\n",
        "\n",
        "titanic_df['Embarked'] = titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0])\n",
        "\n",
        "print(\"Missing values after fillna:\\n\", titanic_df.isnull().sum())\n",
        "\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "titanic_df['Age'] = imputer.fit_transform(titanic_df[['Age']])\n",
        "\n",
        "imputer = SimpleImputer(strategy='most_frequent')\n",
        "titanic_df['Embarked'] = imputer.fit_transform(titanic_df[['Embarked']])\n",
        "\n",
        "print(\"Missing values after SimpleImputer:\\n\", titanic_df.isnull().sum())\n"
      ],
      "metadata": {
        "id": "TLWVYMpaT6S9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "titanic_df = pd.read_csv('C:/Users/Shmuel/Desktop/DI_Bootcamp/Week 8/Day M2/Exercises/Titanic_Dataset.csv')\n",
        "\n",
        "missing_values = titanic_df.isnull().sum()\n",
        "print(\"Columns with missing values:\\n\", missing_values[missing_values > 0])\n",
        "\n",
        "titanic_df['Family Size'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1\n",
        "\n",
        "print(titanic_df[['SibSp', 'Parch', 'Family Size']].head())\n",
        "\n",
        "titanic_df['Title'] = titanic_df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "print(titanic_df[['Name', 'Title']].head())\n",
        "\n",
        "titanic_df = pd.get_dummies(titanic_df, columns=['Sex', 'Embarked', 'Title'], drop_first=True)\n",
        "\n",
        "print(titanic_df.head())\n",
        "\n",
        "scaler = StandardScaler()\n",
        "titanic_df[['Age', 'Fare']] = scaler.fit_transform(titanic_df[['Age', 'Fare']])\n",
        "\n",
        "print(titanic_df[['Age', 'Fare']].head())\n",
        "\n",
        "print(titanic_df.head())\n"
      ],
      "metadata": {
        "id": "YDUfgJkSWRjZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from scipy import stats\n",
        "\n",
        "titanic_df = pd.read_csv('C:/Users/Shmuel/Desktop/DI_Bootcamp/Week 8/Day M2/Exercises/Titanic_Dataset.csv')\n",
        "\n",
        "missing_values = titanic_df.isnull().sum()\n",
        "print(\"Columns with missing values:\\n\", missing_values[missing_values > 0])\n",
        "\n",
        "# Step 1:\n",
        "Q1_age = titanic_df['Age'].quantile(0.25)\n",
        "Q3_age = titanic_df['Age'].quantile(0.75)\n",
        "IQR_age = Q3_age - Q1_age\n",
        "lower_bound_age = Q1_age - 1.5 * IQR_age\n",
        "upper_bound_age = Q3_age + 1.5 * IQR_age\n",
        "outliers_age = titanic_df[(titanic_df['Age'] < lower_bound_age) | (titanic_df['Age'] > upper_bound_age)]\n",
        "print(f'Number of outliers in Age: {outliers_age.shape[0]}')\n",
        "\n",
        "Q1_fare = titanic_df['Fare'].quantile(0.25)\n",
        "Q3_fare = titanic_df['Fare'].quantile(0.75)\n",
        "IQR_fare = Q3_fare - Q1_fare\n",
        "lower_bound_fare = Q1_fare - 1.5 * IQR_fare\n",
        "upper_bound_fare = Q3_fare + 1.5 * IQR_fare\n",
        "outliers_fare = titanic_df[(titanic_df['Fare'] < lower_bound_fare) | (titanic_df['Fare'] > upper_bound_fare)]\n",
        "print(f'Number of outliers in Fare: {outliers_fare.shape[0]}')\n",
        "\n",
        "z_scores_age = stats.zscore(titanic_df['Age'])\n",
        "outliers_age_z = titanic_df[(abs(z_scores_age) > 3)]\n",
        "print(f'Number of outliers in Age using Z-score: {outliers_age_z.shape[0]}')\n",
        "\n",
        "z_scores_fare = stats.zscore(titanic_df['Fare'])\n",
        "outliers_fare_z = titanic_df[(abs(z_scores_fare) > 3)]\n",
        "print(f'Number of outliers in Fare using Z-score: {outliers_fare_z.shape[0]}')\n",
        "\n",
        "# Step 2\n",
        "titanic_df['Age'] = titanic_df['Age'].apply(lambda x: upper_bound_age if x > upper_bound_age else (lower_bound_age if x < lower_bound_age else x))\n",
        "titanic_df['Fare'] = titanic_df['Fare'].apply(lambda x: upper_bound_fare if x > upper_bound_fare else (lower_bound_fare if x < lower_bound_fare else x))\n",
        "\n",
        "print(titanic_df[['Age', 'Fare']].describe())\n"
      ],
      "metadata": {
        "id": "5C7R1Y__WjGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "\n",
        "titanic_df = pd.read_csv('C:/Users/Shmuel/Desktop/DI_Bootcamp/Week 8/Day M2/Exercises/Titanic_Dataset.csv')\n",
        "\n",
        "print(\"Statistical summary before scaling and normalization:\")\n",
        "print(titanic_df.describe())\n",
        "\n",
        "titanic_df['Age'] = titanic_df['Age'].fillna(titanic_df['Age'].median())\n",
        "\n",
        "titanic_df['Embarked'] = titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0])\n",
        "\n",
        "titanic_df['Family Size'] = titanic_df['SibSp'] + titanic_df['Parch'] + 1\n",
        "\n",
        "titanic_df['Title'] = titanic_df['Name'].str.extract('([A-Za-z]+)\\.', expand=False)\n",
        "\n",
        "titanic_df = pd.get_dummies(titanic_df, columns=['Sex', 'Embarked', 'Title'], drop_first=True)\n",
        "\n",
        "columns_to_standardize = ['Age', 'Fare']\n",
        "\n",
        "scaler = StandardScaler()\n",
        "\n",
        "titanic_df[columns_to_standardize] = scaler.fit_transform(titanic_df[columns_to_standardize])\n",
        "\n",
        "print(\"Standardized columns:\")\n",
        "print(titanic_df[columns_to_standardize].head())\n",
        "\n",
        "columns_to_normalize = ['Family Size']\n",
        "\n",
        "min_max_scaler = MinMaxScaler()\n",
        "\n",
        "titanic_df[columns_to_normalize] = min_max_scaler.fit_transform(titanic_df[columns_to_normalize])\n",
        "\n",
        "print(\"Normalized columns:\")\n",
        "print(titanic_df[columns_to_normalize].head())\n",
        "\n",
        "print(\"Statistical summary after scaling and normalization:\")\n",
        "print(titanic_df.describe())\n"
      ],
      "metadata": {
        "id": "lG44DdGYXbfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "titanic_df = pd.read_csv('C:/Users/Shmuel/Desktop/DI_Bootcamp/Week 8/Day M2/Exercises/Titanic_Dataset.csv')\n",
        "\n",
        "titanic_df['Age'] = titanic_df['Age'].fillna(titanic_df['Age'].median())\n",
        "titanic_df['Embarked'] = titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0])\n",
        "\n",
        "categorical_columns = ['Sex', 'Embarked', 'Pclass']\n",
        "print(f\"Categorical columns: {categorical_columns}\")\n",
        "\n",
        "titanic_df = pd.get_dummies(titanic_df, columns=['Sex', 'Embarked'], drop_first=True)\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "titanic_df['Pclass'] = label_encoder.fit_transform(titanic_df['Pclass'])\n",
        "\n",
        "print(titanic_df.head())\n",
        "\n",
        "print(\"Columns after encoding:\")\n",
        "print(titanic_df.columns)\n"
      ],
      "metadata": {
        "id": "RAfQNJ3AYXiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "titanic_df = pd.read_csv('C:/Users/Shmuel/Desktop/DI_Bootcamp/Week 8/Day M2/Exercises/Titanic_Dataset.csv')\n",
        "\n",
        "titanic_df['Age'] = titanic_df['Age'].fillna(titanic_df['Age'].median())\n",
        "titanic_df['Embarked'] = titanic_df['Embarked'].fillna(titanic_df['Embarked'].mode()[0])\n",
        "\n",
        "age_bins = [0, 12, 18, 25, 35, 60, 100]\n",
        "age_labels = ['Child', 'Teen', 'Young Adult', 'Adult', 'Senior Adult', 'Senior']\n",
        "\n",
        "titanic_df['Age Group'] = pd.cut(titanic_df['Age'], bins=age_bins, labels=age_labels)\n",
        "\n",
        "print(titanic_df[['Age', 'Age Group']].head())\n",
        "\n",
        "titanic_df = pd.get_dummies(titanic_df, columns=['Age Group'], drop_first=True)\n",
        "\n",
        "print(titanic_df.head())\n",
        "print(\"Columns after encoding:\")\n",
        "print(titanic_df.columns)\n"
      ],
      "metadata": {
        "id": "qGm1DOJSY3VC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}